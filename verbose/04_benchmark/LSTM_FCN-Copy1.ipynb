{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vobhS7Eg9H3K"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import argparse\n",
    "import glob\n",
    "from tensorboardX import SummaryWriter\n",
    "import pandas as pd\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from utils import data_generator\n",
    "import numpy as np\n",
    "import argparse\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchsummary import summary\n",
    "from torch.nn.modules.module import _addindent\n",
    "from numpy import asarray\n",
    "from numpy import savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcI1wycr9VkR"
   },
   "outputs": [],
   "source": [
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vcAJByI9XiB"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "DATASET = 'Earthquakes'\n",
    "classes = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gS7nvMgh9bZO"
   },
   "outputs": [],
   "source": [
    "path = pathlib.Path('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5fbMI2G9c0L"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(input, labels):\n",
    "    m = input.shape[0]\n",
    "    output = np.zeros((m, labels), dtype=int)\n",
    "    row_index = np.arange(m)\n",
    "    output[row_index, input] = 1\n",
    "    return output\n",
    "\n",
    "def split_xy(data, classes):\n",
    "    X = data[:, 1:]\n",
    "    y = data[:, 0].astype(int)\n",
    "    # hot encode\n",
    "    #y = one_hot_encode(y, classes)\n",
    "    return X, y\n",
    "\n",
    "def create_dataset(X, y, device):\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.long, device=device)\n",
    "    return TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "def load_data(path, classes):\n",
    "    data = np.loadtxt(path)\n",
    "    return split_xy(data, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GXvSnk3X9hJm"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Earthquakes_TRAIN.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-16bbfd621bf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'Earthquakes_TRAIN.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load testing dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'Earthquakes_TEST.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-eff8ff6679b2>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path, classes)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msplit_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_envi/pytorch_py3/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_envi/pytorch_py3/lib/python3.5/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_envi/pytorch_py3/lib/python3.5/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Earthquakes_TRAIN.txt not found."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# load training dataset\n",
    "X_train, y_train = load_data(path/'Earthquakes_TRAIN.txt', classes) \n",
    "\n",
    "# load testing dataset\n",
    "X_test, y_test = load_data(path/'Earthquakes_TEST.txt', classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "AmQx_Tmj9lir",
    "outputId": "f127034a-ccea-45fe-d26d-d03e7b1439b5"
   },
   "outputs": [],
   "source": [
    "print('X_train %s   y_train %s' % (X_train.shape, y_train.shape))\n",
    "print('X_test  %s   y_test  %s' % (X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wREOYx7y9rtu",
    "outputId": "40e7e64f-7345-4192-ff8b-8bc02af362b3"
   },
   "outputs": [],
   "source": [
    "class_0_count = (y_train==0).sum()\n",
    "class_1_count = (y_train==1).sum()\n",
    "\n",
    "class_0_count, class_1_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lN-kaBcZAWmM"
   },
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')     # Default CUDA device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4qqsromnAcCE"
   },
   "outputs": [],
   "source": [
    "train_ds = create_dataset(X_train, y_train, cuda)\n",
    "test_ds  = create_dataset(X_test, y_test, cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OqaSHfliAf40"
   },
   "outputs": [],
   "source": [
    "class_sample_count = [class_0_count, class_1_count] # dataset has 10 class-1 samples, 1 class-2 samples, etc.\n",
    "weights = 1 / torch.Tensor(class_sample_count)\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ufb7tCjtAnCD"
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=False)#, sampler = sampler)\n",
    "test_dl = DataLoader(test_ds, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GcgBAT49AsAW"
   },
   "outputs": [],
   "source": [
    "class BlockLSTM(nn.Module):\n",
    "    def __init__(self, time_steps, num_layers, lstm_hs, dropout=0.8, attention=False):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=time_steps, hidden_size=lstm_hs, num_layers=num_layers)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    def forward(self, x):\n",
    "        # input is of the form (batch_size, num_layers, time_steps), e.g. (128, 1, 512)\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        # lstm layer is of the form (num_layers, batch_size, time_steps)\n",
    "        x, (h_n, c_n) = self.lstm(x)\n",
    "        # dropout layer input shape (Sequence Length, Batch Size, Hidden Size * Num Directions)\n",
    "        y = self.dropout(x)\n",
    "        # output shape is same as Dropout intput\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uD2b5tyWAvdB"
   },
   "outputs": [],
   "source": [
    "class BlockFCNConv(nn.Module):\n",
    "    def __init__(self, in_channel=1, out_channel=128, kernel_size=8, momentum=0.99, epsilon=0.001, squeeze=False):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_channel, out_channel, kernel_size=kernel_size)\n",
    "        self.batch_norm = nn.BatchNorm1d(num_features=out_channel, eps=epsilon, momentum=momentum)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        # input (batch_size, num_variables, time_steps), e.g. (128, 1, 512)\n",
    "        x = self.conv(x)\n",
    "        # input (batch_size, out_channel, L_out)\n",
    "        x = self.batch_norm(x)\n",
    "        # same shape as input\n",
    "        y = self.relu(x)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GxHCCFNwA4iG"
   },
   "outputs": [],
   "source": [
    "class BlockFCN(nn.Module):\n",
    "    def __init__(self, time_steps, channels=[1, 128, 256, 128], kernels=[8, 5, 3], mom=0.99, eps=0.001):\n",
    "        super().__init__()\n",
    "        self.conv1 = BlockFCNConv(channels[0], channels[1], kernels[0], momentum=mom, epsilon=eps, squeeze=True)\n",
    "        self.conv2 = BlockFCNConv(channels[1], channels[2], kernels[1], momentum=mom, epsilon=eps, squeeze=True)\n",
    "        self.conv3 = BlockFCNConv(channels[2], channels[3], kernels[2], momentum=mom, epsilon=eps)\n",
    "        output_size = time_steps - sum(kernels) + len(kernels)\n",
    "        self.global_pooling = nn.AvgPool1d(kernel_size=output_size)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        # apply Global Average Pooling 1D\n",
    "        y = self.global_pooling(x)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VMGtnY5lBBNZ"
   },
   "outputs": [],
   "source": [
    "class LSTMFCN(nn.Module):\n",
    "    def __init__(self, time_steps, num_variables=1, lstm_hs=64, channels=[1, 128, 256, 128]):\n",
    "        super().__init__()\n",
    "        self.lstm_block = BlockLSTM(time_steps, 1, lstm_hs)\n",
    "        self.fcn_block = TCN(time_steps)\n",
    "        self.dense = nn.Linear(channels[-1] + lstm_hs, num_variables)\n",
    "        self.softmax = nn.LogSoftmax(dim=1) #nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        # input is (batch_size, time_steps), it has to be (batch_size, 1, time_steps)\n",
    "        x = x.unsqueeze(1)\n",
    "        # pass input through LSTM block\n",
    "        x1 = self.lstm_block(x)\n",
    "        x1 = torch.squeeze(x1)\n",
    "        # pass input through FCN block\n",
    "        x2 = self.fcn_block(x)\n",
    "        x2 = torch.squeeze(x2)\n",
    "        # concatenate blocks output\n",
    "        x = torch.cat([x1, x2], 1)\n",
    "        # pass through Linear layer\n",
    "        x = self.dense(x)\n",
    "        #x = torch.squeeze(x)\n",
    "        # pass through Softmax activation\n",
    "        y = self.softmax(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OQSm6f0-BC_N",
    "outputId": "d7d12a59-685e-4243-b9fc-12325023ed38"
   },
   "outputs": [],
   "source": [
    "time_steps = X_train.shape[1]\n",
    "num_variables = classes\n",
    "\n",
    "time_steps, num_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "ZhmcLXuIBJ3B",
    "outputId": "6da416a1-8ac4-462d-d467-d50282a5a2e7"
   },
   "outputs": [],
   "source": [
    "model = LSTMFCN(time_steps, num_variables).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "colab_type": "code",
    "id": "-ajg1qNTBM_e",
    "outputId": "6e7161c9-0cf3-41e3-a36a-ddb82d3eaa89"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model summary\n",
    "for m in model.children():\n",
    "    print(\"this is mother\")\n",
    "    print(m.training)#, m)\n",
    "    for j in m.children():\n",
    "        print(j.training, j)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "colab_type": "code",
    "id": "6nx3apQdBgoB",
    "outputId": "74c1543c-a52b-4adf-ab59-c2dcc4b1bf4a"
   },
   "outputs": [],
   "source": [
    "[p.shape for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lk3fpZwABwr0"
   },
   "outputs": [],
   "source": [
    "class SimpleLearner():\n",
    "    def __init__(self, data, model, loss_func, wd = 1e-5):\n",
    "        self.data, self.model, self.loss_func = data, model, loss_func\n",
    "        self.wd = wd\n",
    "    \n",
    "    def update_manualgrad(self, x,y,lr):\n",
    "        y_hat = self.model(x)\n",
    "        # weight decay\n",
    "        w2 = 0.\n",
    "        for p in model.parameters(): w2 += (p**2).sum()\n",
    "        # add to regular loss\n",
    "        loss = self.loss_func(y_hat, y) + w2 * self.wd\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for p in model.parameters():\n",
    "                p.sub_(lr * p.grad)\n",
    "                p.grad.zero_()\n",
    "        return loss.item()\n",
    "\n",
    "    def update(self, x,y,lr):\n",
    "        opt = optim.Adam(self.model.parameters(), lr)\n",
    "        y_hat = self.model(x)\n",
    "        loss = self.loss_func(y_hat, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        return loss.item()\n",
    "\n",
    "    def fit(self, epochs=1, lr=1e-3):\n",
    "        \"\"\"Train the model\"\"\"\n",
    "        losses = []\n",
    "        for i in tqdm(range(epochs)):\n",
    "            for x,y in self.data[0]:\n",
    "                current_loss = self.update(x, y , lr)\n",
    "                losses.append(current_loss)\n",
    "        return losses\n",
    "    \n",
    "    def evaluate(self, X):\n",
    "        \"\"\"Evaluate the given data loader on the model and return predictions\"\"\"\n",
    "        result = None\n",
    "        for x, y in X:\n",
    "            y_hat = self.model.cpu()(x.cpu().data.numpy())\n",
    "            result = y_hat if result is None else np.concatenate((result, y_hat), axis=0)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4OLIOCi8CWra"
   },
   "outputs": [],
   "source": [
    "model = LSTMFCN(time_steps, num_variables).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uwnghGHeCa4w"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# depending on the number of classes, use a Binary Cross Entropy or a Negative Log Likelihood loss for more than two classes\n",
    "loss_func = nn.NLLLoss().cuda() # weight=weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2zW6eiA5Cj1A",
    "outputId": "2ad388ee-9b02-4059-f357-23f64c701e82"
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch import optim\n",
    "lr = 2e-2\n",
    "learner = SimpleLearner([train_dl, test_dl], model, loss_func)\n",
    "losses = learner.fit(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "_YD3yfFgDEOh",
    "outputId": "a594457c-5730-45d8-9a6f-ad83ff97e187"
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "W8YMxrSnDPMH",
    "outputId": "d1b1cdea-e2a3-4532-910b-8b48c21d32b9"
   },
   "outputs": [],
   "source": [
    "test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "colab_type": "code",
    "id": "4yATiSETDwOe",
    "outputId": "4b6f6c66-6929-4bee-d3f9-623b5faf36a4"
   },
   "outputs": [],
   "source": [
    "y_pred = learner.evaluate(test_dl).cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "abvB3tNMEjR4"
   },
   "outputs": [],
   "source": [
    "model = LSTMFCN(time_steps, num_variables).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "TOEGpU3TEmHH",
    "outputId": "49a96b57-8935-4480-a5b2-cdff5c4bf664"
   },
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "from fastai.basics import *\n",
    "data = DataBunch(train_dl=train_dl, valid_dl=test_dl)\n",
    "learner = Learner(data, model, loss_func=loss_func, metrics=accuracy)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "LSTM-FCN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
