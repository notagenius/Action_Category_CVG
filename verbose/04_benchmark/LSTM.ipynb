{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vTDHog-dM_NL"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import argparse\n",
    "import glob\n",
    "from tensorboardX import SummaryWriter\n",
    "import pandas as pd\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E634Ocm-N5j0"
   },
   "outputs": [],
   "source": [
    "def parse_command_line():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-n', '--net', type=str, default='simpleLSTM', help='task to be trained')\n",
    "    parser.add_argument('-f', '--file', type=str, default='simpleLSTM', help='tensorboard location')\n",
    "    parser.add_argument('-r', '--runs', type=str, default='test/simpleLSTM', help='tensorboard location')\n",
    "    parser.add_argument('-b', '--batchsize', type=int, default=64, help='batchsize')\n",
    "    parser.add_argument('-m', '--max', type=int, default=20, help='batchsize')\n",
    "    parser.add_argument('-l', '--force_learning_rate', type=float, default=0.00001, help='setting learning rate')\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Srz8zJtmOCDs"
   },
   "outputs": [],
   "source": [
    "opt = parse_command_line()\n",
    "writer = SummaryWriter(opt.runs)\n",
    "params = { 'batch_size': opt.batchsize, 'shuffle': True, 'num_workers': 10, 'drop_last': True}\n",
    "learning_rate = opt.force_learning_rate\n",
    "\n",
    "data = {'Data_hz': 2, 'Frame_len': 25}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "loAFquISOIQj"
   },
   "outputs": [],
   "source": [
    "def get_filename_type(file):\n",
    "    filename = file.split(\"/\")[-1].split('.')[:-1]\n",
    "    file_type = file.split(\"/\")[-1].split('.')[-1]\n",
    "    return filename, file_type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCHGjY68ON1d"
   },
   "outputs": [],
   "source": [
    "class my_dataset(Dataset):\n",
    "    def __init__(self, csv_path_folder, npy_path_folder, data_hz, frame_len):\n",
    "        \n",
    "        self.data_hz = data_hz\n",
    "        self.frame_len = frame_len\n",
    "\n",
    "        # txt\n",
    "        self.csv_filenames = sorted(glob.glob(csv_path_folder))\n",
    "        self.csv_list_of_dfs = [np.loadtxt(filename, dtype=np.long) for filename in self.csv_filenames]\n",
    "        self.csv_dataframes = {}\n",
    "        self.csv_filename = []\n",
    "        self.csv_result = []\n",
    "        for csv_dataframe, csv_filename in zip(self.csv_list_of_dfs, self.csv_filenames):\n",
    "            tmp_name,_= get_filename_type(csv_filename)\n",
    "            self.csv_filename.append(tmp_name)\n",
    "            self.csv_dataframes[csv_filename] = csv_dataframe\n",
    "        for i in self.csv_list_of_dfs:\n",
    "            for j in range(len(i)-(self.frame_len-1)*self.data_hz):\n",
    "                tmp_list=[]\n",
    "                for k in range(self.frame_len):\n",
    "                    tmp_list.append(i[j+k*self.data_hz].argmax(axis=0))\n",
    "                    #tmp_list.append(i[j+k*self.data_hz])\n",
    "                self.csv_result.append(tmp_list[-1])\n",
    "        self.csv_conbined_df = np.concatenate(self.csv_list_of_dfs)\n",
    "        self.csv_torch_tensor = torch.tensor(self.csv_conbined_df)\n",
    "        print(self.csv_result[0])\n",
    "        # npy\n",
    "        self.npy_filenames = sorted(glob.glob(npy_path_folder))\n",
    "        self.npy_list_of_frames = [np.load(filename) for filename in self.npy_filenames]\n",
    "        self.npy_inputs = {}\n",
    "        self.npy_filename = []\n",
    "        self.npy_result = []\n",
    "\n",
    "        for i in self.npy_list_of_frames:\n",
    "            for j in range(len(i)-(self.frame_len-1)*self.data_hz):\n",
    "                tmp_list=[]\n",
    "                for k in range(self.frame_len):\n",
    "                    tmp_list.append(np.concatenate(i[j+k*self.data_hz]))\n",
    "                self.npy_result.append(tmp_list)\n",
    "\n",
    "        for npy_input, npy_filename in zip(self.npy_list_of_frames, self.npy_filenames):\n",
    "            tmp_name,_= get_filename_type(npy_filename)\n",
    "            if tmp_name not in self.csv_filename:\n",
    "                self.npy_inputs[npy_filename] = npy_input\n",
    "        self.npy_conbined_inputs = np.concatenate(self.npy_list_of_frames, axis=0, out=None)\n",
    "        self.npy_torch_tensor = torch.tensor(self.npy_conbined_inputs)\n",
    "        \n",
    "        print(\"length of input skeleton is:\"+str(len(self.npy_conbined_inputs))+\" mod of batch size is:\"+str(len(self.npy_conbined_inputs)%params['batch_size']))\n",
    "        print(\"length of input label is:\"+str(len(self.csv_conbined_df))+\" mod of batch size is:\"+str(len(self.csv_conbined_df)%params['batch_size']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv_result)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return np.asarray(self.npy_result[index]),np.asarray(self.csv_result[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ogCNSI__OW8B"
   },
   "outputs": [],
   "source": [
    "class BlockLSTM(nn.Module):\n",
    "    def __init__(self, time_steps, num_variables, num_classes, lstm_hs=256, dropout=0.8, attention=False):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=time_steps, hidden_size=lstm_hs, num_layers=num_variables)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        #self.fc = nn.Linear(lstm_hs, num_classes)\n",
    "        self.dense = nn.Linear(lstm_hs, num_classes)\n",
    "        self.softmax = nn.LogSoftmax(dim=1) #nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        # (batch_size, num_variables, time_steps), e.g. (128, 1, 512)\n",
    "        # x = torch.transpose(x, 0, 1)\n",
    "        # (num_variables, batch_size, time_steps)\n",
    "        x,_ = self.lstm(x)\n",
    "        # dropout layer input shape:\n",
    "        # y = self.dropout(x)\n",
    "        # output shape is of the form ()\n",
    "        #y = self.fc(x)\n",
    "        x = self.dense(x[:, -1, :])\n",
    "        #x = torch.squeeze(x)\n",
    "        # pass through Softmax activation\n",
    "        y = self.softmax(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CQmv48K-xCcs"
   },
   "outputs": [],
   "source": [
    "class simpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(simpleLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).cuda()\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).cuda()\n",
    "\n",
    "        out, (h_n, h_c) = self.lstm(x, (h0, c0))\n",
    "\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        #return out\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMO3YlwCWkN3"
   },
   "outputs": [],
   "source": [
    "class SimpleLearner():\n",
    "    def __init__(self, data, model, loss_func, wd = 1e-5):\n",
    "        self.data, self.model, self.loss_func = data , model , loss_func \n",
    "        self.wd = wd\n",
    "    \n",
    "    def update_manualgrad(self, x,y,lr):\n",
    "        y_hat = self.model(x)\n",
    "        # weight decay\n",
    "        w2 = 0.\n",
    "        for p in model.parameters(): w2 += (p**2).sum()\n",
    "        # add to regular loss\n",
    "        loss = self.loss_func(y_hat, y) + w2 * self.wd\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for p in model.parameters():\n",
    "                p.sub_(lr * p.grad)\n",
    "                p.grad.zero_()\n",
    "        return loss.item()\n",
    "\n",
    "    def update(self, x,y,lr):\n",
    "        x = x.view(-1, 1, 2400).cuda()\n",
    "        y = y.cuda()\n",
    "        opt = optim.Adam(self.model.parameters(), lr)\n",
    "        y_hat = self.model(x)\n",
    "        loss = self.loss_func(y_hat, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        return loss.item()\n",
    "\n",
    "    def fit(self, epochs=1, lr=1e-3):\n",
    "        \"\"\"Train the model\"\"\"\n",
    "        losses = []\n",
    "        for i in range(epochs):\n",
    "            for x,y in self.data[0]:\n",
    "                current_loss = self.update(x, y , lr)\n",
    "                losses.append(current_loss)\n",
    "        return losses\n",
    "    \n",
    "    def evaluate(self, X):\n",
    "        \"\"\"Evaluate the given data loader on the model and return predictions\"\"\"\n",
    "        result = None\n",
    "        gt = None\n",
    "        for x, y in X:\n",
    "            x = x.view(-1, 1, 2400).cuda()\n",
    "            #y = y.cuda()\n",
    "            y_hat = self.model(x).cpu().detach().numpy()\n",
    "            result = y_hat.argmax(axis=1) if result is None else np.concatenate((result, y_hat.argmax(axis=1)), axis=0)\n",
    "            gt = y if gt is None else np.concatenate((gt, y), axis=0)\n",
    "        return result, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_evaluation(validation_generator):\n",
    "    y_pred, gt = learner.evaluate(validation_generator)\n",
    "    return y_pred, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "def get_mpca(pred, gt): \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    result = cm.diagonal()\n",
    "    return(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "xA-7_XnlXWgR",
    "outputId": "73873740-9e6c-44d5-cc92-f3b8db5703c6"
   },
   "outputs": [],
   "source": [
    "max_epochs = opt.max\n",
    "max_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LP2gkuBMXyPs"
   },
   "outputs": [],
   "source": [
    "csv_path = {'train':\"/media/data/weiling/Action_Category_CVG/00_datasets/Weiling_data/label_not5/S*.csv\", 'val':\"/media/data/weiling/Action_Category_CVG/00_datasets/Weiling_data/label_5/S*.csv\"}\n",
    "npy_path = {'train':\"/media/data/weiling/Action_Category_CVG/00_datasets/Weiling_data/pose_not5/S*.npy\",'val':\"/media/data/weiling/Action_Category_CVG/00_datasets/Weiling_data/pose_5/S*.npy\"}\n",
    "csv_path = {'train':\"/media/data/weiling/Action_Category_CVG/00_datasets/Weiling_data/fake_label_5/S*.csv\", 'val':\"/media/data/weiling/Action_Category_CVG/00_datasets/Weiling_data/fake_label_5/S*.csv\"}\n",
    "npy_path = {'train':\"/media/data/weiling/Action_Category_CVG/00_datasets/Weiling_data/fake_3d_5/S*.npy\",'val':\"/media/data/weiling/Action_Category_CVG/00_datasets/Weiling_data/fake_3d_5/S*.npy\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uv7OKtbffDTW"
   },
   "outputs": [],
   "source": [
    "model = BlockLSTM(time_steps=2400, num_variables=1, num_classes=10 ).cuda()\n",
    "#model = simpleLSTM(input_size=96, hidden_size=64, num_layers=25, num_classes=10).cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "dACZXae1YSzF",
    "outputId": "bef69f9c-6231-4564-a864-ea1827f53b49"
   },
   "outputs": [],
   "source": [
    "training_set = my_dataset(csv_path['train'], npy_path['train'], data['Data_hz'],data['Frame_len'])\n",
    "training_generator = DataLoader(training_set, **params)\n",
    "validation_set = my_dataset(csv_path['val'], npy_path['val'],data['Data_hz'],data['Frame_len'])\n",
    "validation_generator = DataLoader(validation_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "z8Zo2F64iBd2",
    "outputId": "81b859bf-3d4e-4f71-9461-70caa9ec88fb"
   },
   "outputs": [],
   "source": [
    "# model summary\n",
    "for m in model.children():\n",
    "    print(m.training)#, m)\n",
    "    for j in m.children():\n",
    "        print(j.training, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U1DThhC7iZun"
   },
   "outputs": [],
   "source": [
    "loss_func = nn.NLLLoss().cuda()\n",
    "#loss_func = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vSrmO0crlYFK",
    "outputId": "32932421-6b9e-4915-f172-15e184b5e595"
   },
   "outputs": [],
   "source": [
    "[p.shape for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "WRckho10lZcL",
    "outputId": "5db13f75-65da-403a-a55a-5b9e8db7061f"
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch import optim\n",
    "lr = 2e-2\n",
    "learner = SimpleLearner([training_generator, validation_generator], model, loss_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f6aNgsuzunYb"
   },
   "outputs": [],
   "source": [
    "losses = learner.fit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred,gt = real_evaluation(validation_generator)\n",
    "print(get_mpca(pred, gt))\n",
    "\n",
    "pred,gt = real_evaluation(validation_generator)\n",
    "print(get_acc(pred,gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
